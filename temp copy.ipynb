{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "\n",
    "# Load the stereo WAV file\n",
    "sample_rate, audio_data = wavfile.read('english_long.wav')\n",
    "\n",
    "# Check if the audio is stereo (has 2 channels)\n",
    "if len(audio_data.shape) == 2 and audio_data.shape[1] == 2:\n",
    "    # Extract left channel (channel 1)\n",
    "    left_channel = audio_data[:, 0]\n",
    "    \n",
    "    # Extract right channel (channel 2)\n",
    "    right_channel = audio_data[:, 1]\n",
    "    \n",
    "    # Save left channel as english_long_ch1.wav\n",
    "    wavfile.write('english_long_ch1.wav', sample_rate, left_channel)\n",
    "    \n",
    "    # Save right channel as english_long_ch2.wav\n",
    "    wavfile.write('english_long_ch2.wav', sample_rate, right_channel)\n",
    "    \n",
    "    print(\"Successfully saved both channels as separate files.\")\n",
    "else:\n",
    "    print(\"The input file is not stereo. Please check the audio file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from whisperx.utils import LANGUAGES, TO_LANGUAGE_CODE, optional_float, optional_int, str2bool\n",
    "\n",
    "# Create an argument parser with default values\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"audio\", nargs=\"+\", type=str, help=\"audio file(s) to transcribe\")\n",
    "parser.add_argument(\"--model\", default=\"openai/whisper-large-v3\", help=\"name of the Whisper model to use\")\n",
    "parser.add_argument(\"--model_cache_only\", type=str2bool, default=False, help=\"If True, will not attempt to download models, instead using cached models from --model_dir\")\n",
    "parser.add_argument(\"--model_dir\", type=str, default=None, help=\"the path to save model files; uses ~/.cache/whisper by default\")\n",
    "parser.add_argument(\"--device\", default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"device to use for PyTorch inference\")\n",
    "parser.add_argument(\"--device_index\", default=0, type=int, help=\"device index to use for FasterWhisper inference\")\n",
    "parser.add_argument(\"--batch_size\", default=4, type=int, help=\"the preferred batch size for inference\")\n",
    "parser.add_argument(\"--compute_type\", default=\"float16\", type=str, choices=[\"float16\", \"float32\", \"int8\"], help=\"compute type for computation\")\n",
    "parser.add_argument(\"--use_openai_whisper\", type=str2bool, default=False, help=\"use OpenAI Whisper from Hugging Face instead of Faster Whisper\")\n",
    "\n",
    "parser.add_argument(\"--output_dir\", \"-o\", type=str, default=\".\", help=\"directory to save the outputs\")\n",
    "parser.add_argument(\"--output_format\", \"-f\", type=str, default=\"all\", choices=[\"all\", \"srt\", \"vtt\", \"txt\", \"tsv\", \"json\", \"aud\"], help=\"format of the output file; if not specified, all available formats will be produced\")\n",
    "parser.add_argument(\"--verbose\", type=str2bool, default=None, help=\"whether to print out the progress and debug messages\")\n",
    "\n",
    "parser.add_argument(\"--task\", type=str, default=\"transcribe\", choices=[\"transcribe\", \"translate\"], help=\"whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')\")\n",
    "parser.add_argument(\"--language\", type=str, default=None, choices=sorted(LANGUAGES.keys()) + sorted([k.title() for k in TO_LANGUAGE_CODE.keys()]), help=\"language spoken in the audio, specify None to perform language detection\")\n",
    "\n",
    "# alignment params\n",
    "parser.add_argument(\"--align_model\", default=None, help=\"Name of phoneme-level ASR model to do alignment\")\n",
    "parser.add_argument(\"--interpolate_method\", default=\"nearest\", choices=[\"nearest\", \"linear\", \"ignore\"], help=\"For word .srt, method to assign timestamps to non-aligned words, or merge them into neighbouring.\")\n",
    "parser.add_argument(\"--no_align\", action='store_true', help=\"Do not perform phoneme alignment\")\n",
    "parser.add_argument(\"--return_char_alignments\", action='store_true', help=\"Return character-level alignments in the output json file\")\n",
    "\n",
    "# vad params\n",
    "parser.add_argument(\"--vad_method\", type=str, default=\"silero_custom\", choices=[\"pyannote\", \"silero\", \"silero_custom\"], help=\"VAD method to be used\")\n",
    "parser.add_argument(\"--vad_onset\", type=float, default=0.500, help=\"Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected\")\n",
    "parser.add_argument(\"--vad_offset\", type=float, default=0.363, help=\"Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.\")\n",
    "parser.add_argument(\"--chunk_size\", type=int, default=30, help=\"Chunk size for merging VAD segments. Default is 30, reduce this if the chunk is too long.\")\n",
    "parser.add_argument(\"--vad_onnx\", type=str2bool, default=True, help=\"If `True`, use the ONNX version of the Silero VAD model.\")\n",
    "parser.add_argument(\"--silero_merge_cutoff\", type=float, default=0.1, help=\"The merge cutoff for the Silero VAD model.\")\n",
    "\n",
    "# diarization params\n",
    "parser.add_argument(\"--diarize\", action=\"store_true\", help=\"Apply diarization to assign speaker labels to each segment/word\")\n",
    "parser.add_argument(\"--min_speakers\", default=None, type=int, help=\"Minimum number of speakers to in audio file\")\n",
    "parser.add_argument(\"--max_speakers\", default=None, type=int, help=\"Maximum number of speakers to in audio file\")\n",
    "\n",
    "parser.add_argument(\"--temperature\", type=float, default=0, help=\"temperature to use for sampling\")\n",
    "parser.add_argument(\"--best_of\", type=optional_int, default=5, help=\"number of candidates when sampling with non-zero temperature\")\n",
    "parser.add_argument(\"--beam_size\", type=optional_int, default=5, help=\"number of beams in beam search, only applicable when temperature is zero\")\n",
    "parser.add_argument(\"--patience\", type=float, default=1.0, help=\"optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search\")\n",
    "parser.add_argument(\"--length_penalty\", type=float, default=1.0, help=\"optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default\")\n",
    "\n",
    "parser.add_argument(\"--suppress_tokens\", type=str, default=\"-1\", help=\"comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations\")\n",
    "parser.add_argument(\"--suppress_numerals\", action=\"store_true\", help=\"whether to suppress numeric symbols and currency symbols during sampling, since wav2vec2 cannot align them correctly\")\n",
    "\n",
    "parser.add_argument(\"--initial_prompt\", type=str, default=None, help=\"optional text to provide as a prompt for the first window.\")\n",
    "parser.add_argument(\"--condition_on_previous_text\", type=str2bool, default=False, help=\"if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop\")\n",
    "parser.add_argument(\"--fp16\", type=str2bool, default=True, help=\"whether to perform inference in fp16; True by default\")\n",
    "\n",
    "parser.add_argument(\"--temperature_increment_on_fallback\", type=optional_float, default=0.2, help=\"temperature to increase when falling back when the decoding fails to meet either of the thresholds below\")\n",
    "parser.add_argument(\"--compression_ratio_threshold\", type=optional_float, default=2.4, help=\"if the gzip compression ratio is higher than this value, treat the decoding as failed\")\n",
    "parser.add_argument(\"--logprob_threshold\", type=optional_float, default=-1.0, help=\"if the average log probability is lower than this value, treat the decoding as failed\")\n",
    "parser.add_argument(\"--no_speech_threshold\", type=optional_float, default=0.6, help=\"if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence\")\n",
    "\n",
    "parser.add_argument(\"--max_line_width\", type=optional_int, default=None, help=\"(not possible with --no_align) the maximum number of characters in a line before breaking the line\")\n",
    "parser.add_argument(\"--max_line_count\", type=optional_int, default=None, help=\"(not possible with --no_align) the maximum number of lines in a segment\")\n",
    "parser.add_argument(\"--highlight_words\", type=str2bool, default=False, help=\"(not possible with --no_align) underline each word as it is spoken in srt and vtt\")\n",
    "parser.add_argument(\"--segment_resolution\", type=str, default=\"sentence\", choices=[\"sentence\", \"chunk\"], help=\"(not possible with --no_align) the maximum number of characters in a line before breaking the line\")\n",
    "\n",
    "parser.add_argument(\"--threads\", type=optional_int, default=0, help=\"number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS\")\n",
    "\n",
    "parser.add_argument(\"--hf_token\", type=str, default=None, help=\"Hugging Face Access Token to access PyAnnote gated models\")\n",
    "\n",
    "parser.add_argument(\"--print_progress\", type=str2bool, default=False, help=\"if True, progress will be printed in transcribe() and align() methods.\")\n",
    "\n",
    "# Create an args object with default values\n",
    "args = parser.parse_args(['english_long_ch1.wav'])  # Default audio file\n",
    "\n",
    "# Override with specific values if needed\n",
    "args.model = \"openai/whisper-large-v3\"\n",
    "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args.use_openai_whisper = True\n",
    "args.compute_type = \"float16\"\n",
    "args.language = \"en\"\n",
    "args.verbose = True\n",
    "\n",
    "model_name: str = args.model\n",
    "batch_size: int = args.batch_size\n",
    "model_dir: str = args.model_dir\n",
    "model_cache_only: bool = args.model_cache_only\n",
    "output_dir: str = args.output_dir\n",
    "output_format: str = args.output_format\n",
    "device: str = args.device\n",
    "device_index: int = args.device_index\n",
    "compute_type: str = args.compute_type\n",
    "verbose: bool = args.verbose\n",
    "use_openai_whisper: bool = args.use_openai_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "asr_options = {\n",
    "    \"beam_size\": args.beam_size,\n",
    "    \"patience\": args.patience,\n",
    "    \"length_penalty\": args.length_penalty,\n",
    "    \"suppress_tokens\": [int(x) for x in args.suppress_tokens.split(\",\")],\n",
    "    \"suppress_numerals\": args.suppress_numerals,\n",
    "}\n",
    "\n",
    "\n",
    "hf_token: str = args.hf_token\n",
    "vad_method: str = args.vad_method\n",
    "vad_onset: float = args.vad_onset\n",
    "vad_offset: float = args.vad_offset\n",
    "chunk_size: int = args.chunk_size\n",
    "\n",
    "diarize: bool = args.diarize\n",
    "min_speakers: int = args.min_speakers\n",
    "max_speakers: int = args.max_speakers\n",
    "print_progress: bool = args.print_progress\n",
    "task = args.task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisperx.transcribe import *\n",
    "\n",
    "model = load_openai_model(\n",
    "    model_name, \n",
    "    device=device, \n",
    "    device_index=device_index, \n",
    "    download_root=model_dir, \n",
    "    compute_type=compute_type, \n",
    "    language=None,\n",
    "    asr_options=asr_options, \n",
    "    vad_method=vad_method, \n",
    "    vad_options={\"chunk_size\":chunk_size, \"vad_onset\": vad_onset, \"vad_offset\": vad_offset}, \n",
    "    task=task,\n",
    "    local_files_only=model_cache_only,\n",
    "    return_token_probabilities=use_openai_whisper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisperx.asr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio =\"examples/english_long_ch1.wav\"\n",
    "audio =\"examples/hindi.wav\"\n",
    "if isinstance(audio, str):\n",
    "    audio = load_audio(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process audio and merge chunks as defined by the respective VAD child class \n",
    "# In case vad_model is manually assigned (see 'load_model') follow the functionality of pyannote toolkit\n",
    "if issubclass(type(model.vad_model), Vad):\n",
    "    waveform = model.vad_model.preprocess_audio(audio)\n",
    "    merge_chunks =  model.vad_model.merge_chunks\n",
    "else:\n",
    "    waveform = Pyannote.preprocess_audio(audio)\n",
    "    merge_chunks = Pyannote.merge_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_segments = model.vad_model({\"waveform\": waveform, \"sample_rate\": SAMPLE_RATE})\n",
    "vad_segments = merge_chunks(\n",
    "    vad_segments,\n",
    "    chunk_size,\n",
    "    onset=model._vad_params[\"vad_onset\"],\n",
    "    offset=model._vad_params[\"vad_offset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract segment durations\n",
    "durations = [round(i[\"end\"]-i[\"start\"], 2) for i in vad_segments]\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(durations, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Segment Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of VAD Segment Durations')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate the time gaps between consecutive segments\n",
    "gaps = []\n",
    "for i in range(1, len(vad_segments)):\n",
    "    current_start = vad_segments[i][\"start\"]\n",
    "    previous_end = vad_segments[i-1][\"end\"]\n",
    "    gap = round(current_start - previous_end, 2)\n",
    "    gaps.append(gap)\n",
    "    \n",
    "gaps = [i for i in gaps if i < 1]\n",
    "\n",
    "# Create histogram of gaps between segments\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(gaps, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "plt.xlabel('Gap Duration (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Gaps Between VAD Segments')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "languages = []\n",
    "for segment in tqdm(vad_segments):\n",
    "    start_frame = int(segment['start'] * SAMPLE_RATE)\n",
    "    end_frame = int(segment['end'] * SAMPLE_RATE)\n",
    "    audio_segment = audio[start_frame:end_frame]\n",
    "    languages.append(model.detect_language(audio_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(audio, segments):\n",
    "    final_segments = []\n",
    "    for seg in segments:\n",
    "        f1 = int(seg['start'] * SAMPLE_RATE)\n",
    "        f2 = int(seg['end'] * SAMPLE_RATE)\n",
    "        final_segments.append({'inputs': audio[f1:f2]})\n",
    "    return final_segments\n",
    "\n",
    "final_segments = data(audio, vad_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = [model.preprocess_audio(audio_segment[\"inputs\"]) for audio_segment in final_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = torch.stack(features_all)\n",
    "batches = torch.split(complete_data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ids = {}\n",
    "for i in set([i[0] for i in languages]):\n",
    "    forced_decoder_ids = model.processor.get_decoder_prompt_ids(\n",
    "        task=\"transcribe\", \n",
    "        language=i, \n",
    "        no_timestamps=model.options.without_timestamps\n",
    "    )\n",
    "    decoder_ids[i] = forced_decoder_ids    \n",
    "\n",
    "decoder_ids[\"hi\"] = model.processor.get_decoder_prompt_ids(\n",
    "        task=\"transcribe\", \n",
    "        language=\"hi\", \n",
    "        no_timestamps=model.options.without_timestamps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress tokens if needed\n",
    "if model.suppress_numerals:\n",
    "    suppress_tokens = list(set(model.options.suppress_tokens + model.numeral_symbol_tokens))\n",
    "else:\n",
    "    suppress_tokens = model.options.suppress_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\n",
    "    \"max_new_tokens\": model.options.max_new_tokens,\n",
    "    \"num_beams\": model.options.num_beams,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"temperature\": model.options.temperature,\n",
    "    \"repetition_penalty\": model.options.repetition_penalty,\n",
    "    \"no_repeat_ngram_size\": model.options.no_repeat_ngram_size,\n",
    "    \"length_penalty\": model.options.length_penalty,\n",
    "    \"return_dict_in_generate\": model.options.return_token_probabilities,\n",
    "    \"output_scores\": model.options.return_token_probabilities,\n",
    "}\n",
    "\n",
    "if suppress_tokens:\n",
    "    gen_kwargs[\"suppress_tokens\"] = suppress_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "from tqdm import tqdm\n",
    "for batch in tqdm(batches):\n",
    "    with torch.no_grad():\n",
    "        outputs = model.model.generate(\n",
    "            batch,\n",
    "            forced_decoder_ids=[decoder_ids[i[0]] for i in languages],\n",
    "            **gen_kwargs\n",
    "        )\n",
    "        out.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in batches:\n",
    "    with torch.no_grad():\n",
    "        outputs = model.model.generate(\n",
    "            batch,\n",
    "            # forced_decoder_ids=decoder_ids[\"hi\"],\n",
    "            return_timestamps=True,\n",
    "            **gen_kwargs\n",
    "        )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[\"segments\"][0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.processor.decode(outputs.sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = outputs.sequences\n",
    "scores = outputs.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = sequences[0].cpu().tolist()\n",
    "transcription = model.processor.decode(sequence, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(i) for i in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_probs = []\n",
    "for i, token in enumerate(sequences[0].cpu().tolist()): # Ignore special tokens (4 in beginning and 1 in end)\n",
    "    decoded_token = model.processor.decode([token])\n",
    "    probs = torch.nn.functional.softmax(scores[i][0], dim=-1)\n",
    "    token_probs.append({\n",
    "        \"token\": decoded_token,\n",
    "        \"probability\": round(probs[token].item(), 3)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/v2v/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from whisperx.utils import LANGUAGES, TO_LANGUAGE_CODE, optional_float, optional_int, str2bool\n",
    "\n",
    "# Create an argument parser with default values\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument(\"audio\", nargs=\"+\", type=str, help=\"audio file(s) to transcribe\")\n",
    "parser.add_argument(\"--model\", default=\"openai/whisper-large-v3\", help=\"name of the Whisper model to use\")\n",
    "parser.add_argument(\"--model_cache_only\", type=str2bool, default=False, help=\"If True, will not attempt to download models, instead using cached models from --model_dir\")\n",
    "parser.add_argument(\"--model_dir\", type=str, default=None, help=\"the path to save model files; uses ~/.cache/whisper by default\")\n",
    "parser.add_argument(\"--device\", default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"device to use for PyTorch inference\")\n",
    "parser.add_argument(\"--device_index\", default=0, type=int, help=\"device index to use for FasterWhisper inference\")\n",
    "parser.add_argument(\"--batch_size\", default=4, type=int, help=\"the preferred batch size for inference\")\n",
    "parser.add_argument(\"--compute_type\", default=\"float16\", type=str, choices=[\"float16\", \"float32\", \"int8\"], help=\"compute type for computation\")\n",
    "parser.add_argument(\"--use_openai_whisper\", type=str2bool, default=False, help=\"use OpenAI Whisper from Hugging Face instead of Faster Whisper\")\n",
    "\n",
    "parser.add_argument(\"--output_dir\", \"-o\", type=str, default=\".\", help=\"directory to save the outputs\")\n",
    "parser.add_argument(\"--output_format\", \"-f\", type=str, default=\"all\", choices=[\"all\", \"srt\", \"vtt\", \"txt\", \"tsv\", \"json\", \"aud\"], help=\"format of the output file; if not specified, all available formats will be produced\")\n",
    "parser.add_argument(\"--verbose\", type=str2bool, default=None, help=\"whether to print out the progress and debug messages\")\n",
    "\n",
    "parser.add_argument(\"--task\", type=str, default=\"transcribe\", choices=[\"transcribe\", \"translate\"], help=\"whether to perform X->X speech recognition ('transcribe') or X->English translation ('translate')\")\n",
    "parser.add_argument(\"--language\", type=str, default=None, choices=sorted(LANGUAGES.keys()) + sorted([k.title() for k in TO_LANGUAGE_CODE.keys()]), help=\"language spoken in the audio, specify None to perform language detection\")\n",
    "\n",
    "# alignment params\n",
    "parser.add_argument(\"--align_model\", default=None, help=\"Name of phoneme-level ASR model to do alignment\")\n",
    "parser.add_argument(\"--interpolate_method\", default=\"nearest\", choices=[\"nearest\", \"linear\", \"ignore\"], help=\"For word .srt, method to assign timestamps to non-aligned words, or merge them into neighbouring.\")\n",
    "parser.add_argument(\"--no_align\", action='store_true', help=\"Do not perform phoneme alignment\")\n",
    "parser.add_argument(\"--return_char_alignments\", action='store_true', help=\"Return character-level alignments in the output json file\")\n",
    "\n",
    "# vad params\n",
    "parser.add_argument(\"--vad_method\", type=str, default=\"silero_custom\", choices=[\"pyannote\", \"silero\", \"silero_custom\"], help=\"VAD method to be used\")\n",
    "parser.add_argument(\"--vad_onset\", type=float, default=0.500, help=\"Onset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected\")\n",
    "parser.add_argument(\"--vad_offset\", type=float, default=0.363, help=\"Offset threshold for VAD (see pyannote.audio), reduce this if speech is not being detected.\")\n",
    "parser.add_argument(\"--chunk_size\", type=int, default=30, help=\"Chunk size for merging VAD segments. Default is 30, reduce this if the chunk is too long.\")\n",
    "parser.add_argument(\"--vad_onnx\", type=str2bool, default=True, help=\"If `True`, use the ONNX version of the Silero VAD model.\")\n",
    "parser.add_argument(\"--silero_merge_cutoff\", type=float, default=0.1, help=\"The merge cutoff for the Silero VAD model.\")\n",
    "\n",
    "# diarization params\n",
    "parser.add_argument(\"--diarize\", action=\"store_true\", help=\"Apply diarization to assign speaker labels to each segment/word\")\n",
    "parser.add_argument(\"--min_speakers\", default=None, type=int, help=\"Minimum number of speakers to in audio file\")\n",
    "parser.add_argument(\"--max_speakers\", default=None, type=int, help=\"Maximum number of speakers to in audio file\")\n",
    "\n",
    "parser.add_argument(\"--temperature\", type=float, default=0, help=\"temperature to use for sampling\")\n",
    "parser.add_argument(\"--best_of\", type=optional_int, default=5, help=\"number of candidates when sampling with non-zero temperature\")\n",
    "parser.add_argument(\"--beam_size\", type=optional_int, default=5, help=\"number of beams in beam search, only applicable when temperature is zero\")\n",
    "parser.add_argument(\"--patience\", type=float, default=1.0, help=\"optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search\")\n",
    "parser.add_argument(\"--length_penalty\", type=float, default=1.0, help=\"optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default\")\n",
    "\n",
    "parser.add_argument(\"--suppress_tokens\", type=str, default=\"-1\", help=\"comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations\")\n",
    "parser.add_argument(\"--suppress_numerals\", action=\"store_true\", help=\"whether to suppress numeric symbols and currency symbols during sampling, since wav2vec2 cannot align them correctly\")\n",
    "\n",
    "parser.add_argument(\"--initial_prompt\", type=str, default=None, help=\"optional text to provide as a prompt for the first window.\")\n",
    "parser.add_argument(\"--condition_on_previous_text\", type=str2bool, default=False, help=\"if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop\")\n",
    "parser.add_argument(\"--fp16\", type=str2bool, default=True, help=\"whether to perform inference in fp16; True by default\")\n",
    "\n",
    "parser.add_argument(\"--temperature_increment_on_fallback\", type=optional_float, default=0.2, help=\"temperature to increase when falling back when the decoding fails to meet either of the thresholds below\")\n",
    "parser.add_argument(\"--compression_ratio_threshold\", type=optional_float, default=2.4, help=\"if the gzip compression ratio is higher than this value, treat the decoding as failed\")\n",
    "parser.add_argument(\"--logprob_threshold\", type=optional_float, default=-1.0, help=\"if the average log probability is lower than this value, treat the decoding as failed\")\n",
    "parser.add_argument(\"--no_speech_threshold\", type=optional_float, default=0.6, help=\"if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence\")\n",
    "\n",
    "parser.add_argument(\"--max_line_width\", type=optional_int, default=None, help=\"(not possible with --no_align) the maximum number of characters in a line before breaking the line\")\n",
    "parser.add_argument(\"--max_line_count\", type=optional_int, default=None, help=\"(not possible with --no_align) the maximum number of lines in a segment\")\n",
    "parser.add_argument(\"--highlight_words\", type=str2bool, default=False, help=\"(not possible with --no_align) underline each word as it is spoken in srt and vtt\")\n",
    "parser.add_argument(\"--segment_resolution\", type=str, default=\"sentence\", choices=[\"sentence\", \"chunk\"], help=\"(not possible with --no_align) the maximum number of characters in a line before breaking the line\")\n",
    "\n",
    "parser.add_argument(\"--threads\", type=optional_int, default=0, help=\"number of threads used by torch for CPU inference; supercedes MKL_NUM_THREADS/OMP_NUM_THREADS\")\n",
    "\n",
    "parser.add_argument(\"--hf_token\", type=str, default=None, help=\"Hugging Face Access Token to access PyAnnote gated models\")\n",
    "\n",
    "parser.add_argument(\"--print_progress\", type=str2bool, default=False, help=\"if True, progress will be printed in transcribe() and align() methods.\")\n",
    "\n",
    "# Create an args object with default values\n",
    "args = parser.parse_args(['english_long_ch1.wav'])  # Default audio file\n",
    "\n",
    "# Override with specific values if needed\n",
    "args.model = \"openai/whisper-large-v3\"\n",
    "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "args.use_openai_whisper = True\n",
    "args.compute_type = \"float16\"\n",
    "args.language = \"en\"\n",
    "args.verbose = True\n",
    "\n",
    "model_name: str = args.model\n",
    "batch_size: int = args.batch_size\n",
    "model_dir: str = args.model_dir\n",
    "model_cache_only: bool = args.model_cache_only\n",
    "output_dir: str = args.output_dir\n",
    "output_format: str = args.output_format\n",
    "device: str = args.device\n",
    "device_index: int = args.device_index\n",
    "compute_type: str = args.compute_type\n",
    "verbose: bool = args.verbose\n",
    "use_openai_whisper: bool = args.use_openai_whisper\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "asr_options = {\n",
    "    \"beam_size\": args.beam_size,\n",
    "    \"patience\": args.patience,\n",
    "    \"length_penalty\": args.length_penalty,\n",
    "    \"suppress_tokens\": [int(x) for x in args.suppress_tokens.split(\",\")],\n",
    "    \"suppress_numerals\": args.suppress_numerals,\n",
    "}\n",
    "\n",
    "\n",
    "hf_token: str = args.hf_token\n",
    "vad_method: str = args.vad_method\n",
    "vad_onset: float = args.vad_onset\n",
    "vad_offset: float = args.vad_offset\n",
    "chunk_size: int = args.chunk_size\n",
    "\n",
    "diarize: bool = args.diarize\n",
    "min_speakers: int = args.min_speakers\n",
    "max_speakers: int = args.max_speakers\n",
    "print_progress: bool = args.print_progress\n",
    "task = args.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whisperx.transcribe import *\n",
    "from whisperx.asr import *\n",
    "faster_whisper_threads = 4\n",
    "if (threads := args.threads) > 0:\n",
    "    torch.set_num_threads(threads)\n",
    "    faster_whisper_threads = threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      ">>Performing voice activity detection using Silero...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\n",
    "        \"large-v3-turbo\", \n",
    "        device=device, \n",
    "        device_index=device_index, \n",
    "        download_root=model_dir, \n",
    "        compute_type=compute_type, \n",
    "        language=None, \n",
    "        asr_options=asr_options, \n",
    "        vad_method=vad_method, \n",
    "        vad_options={\"chunk_size\":chunk_size, \"vad_onset\": vad_onset, \"vad_offset\": vad_offset}, \n",
    "        task=task,\n",
    "        local_files_only=model_cache_only,\n",
    "        threads=faster_whisper_threads\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting language for segments: 100%|██████████| 56/56 [00:04<00:00, 12.84it/s]\n",
      "Processing segments of language: en: 100%|██████████| 218/218 [00:14<00:00, 15.01it/s]\n"
     ]
    }
   ],
   "source": [
    "out = model.transcribe(\"examples/english_long_ch1.wav\", batch_size=64, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segments': [{'text': ' Hello, my name is Tony Chiquilla.',\n",
       "   'start': 0.768,\n",
       "   'end': 3.136,\n",
       "   'language': 'en'},\n",
       "  {'text': ' and', 'start': 3.808, 'end': 4.288, 'language': 'en'},\n",
       "  {'text': ' I generally prefer.',\n",
       "   'start': 4.416,\n",
       "   'end': 5.568,\n",
       "   'language': 'en'},\n",
       "  {'text': ' eating at home.', 'start': 5.856, 'end': 6.496, 'language': 'en'},\n",
       "  {'text': ' Hello Andy.', 'start': 10.144, 'end': 10.88, 'language': 'en'},\n",
       "  {'text': ' How are you?', 'start': 11.904, 'end': 12.288, 'language': 'en'},\n",
       "  {'text': ' Good.', 'start': 13.664, 'end': 13.952, 'language': 'en'},\n",
       "  {'text': \" You have any idea what's going on?\",\n",
       "   'start': 14.528,\n",
       "   'end': 15.712,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah.', 'start': 19.136, 'end': 19.488, 'language': 'en'},\n",
       "  {'text': \" What's your preference?\",\n",
       "   'start': 20.256,\n",
       "   'end': 21.216,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 24.672, 'end': 24.896, 'language': 'en'},\n",
       "  {'text': \" I'm eating at home\",\n",
       "   'start': 31.744,\n",
       "   'end': 32.512,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Uh,', 'start': 34.976, 'end': 35.072, 'language': 'en'},\n",
       "  {'text': ' um,', 'start': 35.392, 'end': 35.584, 'language': 'en'},\n",
       "  {'text': ' No.', 'start': 37.376, 'end': 37.728, 'language': 'en'},\n",
       "  {'text': ' uh...', 'start': 37.888, 'end': 38.624, 'language': 'en'},\n",
       "  {'text': ' enjoy eating at home better than',\n",
       "   'start': 38.784,\n",
       "   'end': 40.416,\n",
       "   'language': 'en'},\n",
       "  {'text': ' mean casual.', 'start': 40.8, 'end': 41.568, 'language': 'en'},\n",
       "  {'text': ' Periodic dining out is fine,',\n",
       "   'start': 42.304,\n",
       "   'end': 43.968,\n",
       "   'language': 'en'},\n",
       "  {'text': ' generally speaking, like eating at home.',\n",
       "   'start': 44.48,\n",
       "   'end': 45.952,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Wow.', 'start': 51.776, 'end': 52.128, 'language': 'en'},\n",
       "  {'text': ' Well, that makes a difference.',\n",
       "   'start': 54.592,\n",
       "   'end': 55.52,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah.', 'start': 56.32, 'end': 56.832, 'language': 'en'},\n",
       "  {'text': ' I live in Frederick, Maryland.',\n",
       "   'start': 58.304,\n",
       "   'end': 60.032,\n",
       "   'language': 'en'},\n",
       "  {'text': ' a lot.', 'start': 61.504, 'end': 61.856, 'language': 'en'},\n",
       "  {'text': ' smaller town.', 'start': 62.432, 'end': 63.104, 'language': 'en'},\n",
       "  {'text': ' Yes.', 'start': 63.392, 'end': 63.776, 'language': 'en'},\n",
       "  {'text': ' think that was it.',\n",
       "   'start': 67.776,\n",
       "   'end': 68.384,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah.', 'start': 69.568, 'end': 69.792, 'language': 'en'},\n",
       "  {'text': ' I think it was.',\n",
       "   'start': 71.008,\n",
       "   'end': 71.552,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah, I think that was the only question.',\n",
       "   'start': 72.0,\n",
       "   'end': 73.344,\n",
       "   'language': 'en'},\n",
       "  {'text': \" Is this the first time you've gotten one of these calls?\",\n",
       "   'start': 74.24,\n",
       "   'end': 76.288,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah, likewise.',\n",
       "   'start': 77.024,\n",
       "   'end': 77.792,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yes.', 'start': 77.952, 'end': 78.272, 'language': 'en'},\n",
       "  {'text': \" Likewise, I have a friend who's\",\n",
       "   'start': 82.528,\n",
       "   'end': 84.32,\n",
       "   'language': 'en'},\n",
       "  {'text': ' who turned me on to this, who works for NIST.',\n",
       "   'start': 84.928,\n",
       "   'end': 87.296,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 87.424, 'end': 87.488, 'language': 'en'},\n",
       "  {'text': ' sent me an email about it.',\n",
       "   'start': 88.096,\n",
       "   'end': 88.992,\n",
       "   'language': 'en'},\n",
       "  {'text': \" I guess he's working on some of the programming behind this,\",\n",
       "   'start': 89.344,\n",
       "   'end': 91.712,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Gotcha.', 'start': 100.0, 'end': 100.352, 'language': 'en'},\n",
       "  {'text': ' Okay.', 'start': 103.04, 'end': 103.648, 'language': 'en'},\n",
       "  {'text': ' So now what happens?',\n",
       "   'start': 103.808,\n",
       "   'end': 104.672,\n",
       "   'language': 'en'},\n",
       "  {'text': \" We stopped talking. They'll come back online.\",\n",
       "   'start': 110.176,\n",
       "   'end': 111.808,\n",
       "   'language': 'en'},\n",
       "  {'text': \" We're supposed to talk for 10 minutes.\",\n",
       "   'start': 114.272,\n",
       "   'end': 115.488,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah, I did read something about 10 minutes.',\n",
       "   'start': 118.624,\n",
       "   'end': 120.992,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Is it snowing up there?',\n",
       "   'start': 127.328,\n",
       "   'end': 128.48,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 128.672, 'end': 128.704, 'language': 'en'},\n",
       "  {'text': ' Likewise.', 'start': 130.656, 'end': 131.04, 'language': 'en'},\n",
       "  {'text': ' Where are you in New York?',\n",
       "   'start': 131.168,\n",
       "   'end': 131.968,\n",
       "   'language': 'en'},\n",
       "  {'text': ' in Manhattan.',\n",
       "   'start': 133.44,\n",
       "   'end': 134.016,\n",
       "   'language': 'en'},\n",
       "  {'text': ' of my best friends lives on the',\n",
       "   'start': 135.104,\n",
       "   'end': 136.224,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Upper West Side at 87th and Columbus.',\n",
       "   'start': 136.8,\n",
       "   'end': 138.72,\n",
       "   'language': 'en'},\n",
       "  {'text': ' right in the neighborhood.',\n",
       "   'start': 141.536,\n",
       "   'end': 142.176,\n",
       "   'language': 'en'},\n",
       "  {'text': \" I think it's the Jackson Hole.\",\n",
       "   'start': 142.816,\n",
       "   'end': 144.8,\n",
       "   'language': 'en'},\n",
       "  {'text': \" That's right on the\",\n",
       "   'start': 146.592,\n",
       "   'end': 147.232,\n",
       "   'language': 'en'},\n",
       "  {'text': \" Yeah, it's right on the first floor of the building he's in.\",\n",
       "   'start': 148.0,\n",
       "   'end': 150.272,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Mm-hmm.', 'start': 151.968, 'end': 152.256, 'language': 'en'},\n",
       "  {'text': ' Yep.', 'start': 152.896, 'end': 153.056, 'language': 'en'},\n",
       "  {'text': ' any times.', 'start': 153.568, 'end': 154.176, 'language': 'en'},\n",
       "  {'text': ' um,', 'start': 156.896, 'end': 157.216, 'language': 'en'},\n",
       "  {'text': ' Frederick, Maryland, where an hour',\n",
       "   'start': 157.408,\n",
       "   'end': 158.72,\n",
       "   'language': 'en'},\n",
       "  {'text': ' north of Washington, D.C.,',\n",
       "   'start': 158.976,\n",
       "   'end': 160.832,\n",
       "   'language': 'en'},\n",
       "  {'text': ' in about an hour.',\n",
       "   'start': 162.016,\n",
       "   'end': 163.36,\n",
       "   'language': 'en'},\n",
       "  {'text': ' west of Baltimore.',\n",
       "   'start': 163.488,\n",
       "   'end': 164.544,\n",
       "   'language': 'en'},\n",
       "  {'text': ' So.', 'start': 166.656, 'end': 167.008, 'language': 'en'},\n",
       "  {'text': \" and it's snowing here, we have about\",\n",
       "   'start': 167.872,\n",
       "   'end': 169.376,\n",
       "   'language': 'en'},\n",
       "  {'text': ' eight inches, eight to 10 inches of snow.',\n",
       "   'start': 169.952,\n",
       "   'end': 171.808,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Yeah.', 'start': 181.056, 'end': 181.312, 'language': 'en'},\n",
       "  {'text': \" like we're...\",\n",
       "   'start': 181.44,\n",
       "   'end': 181.856,\n",
       "   'language': 'en'},\n",
       "  {'text': ' in that neighborhood too.',\n",
       "   'start': 182.016,\n",
       "   'end': 183.072,\n",
       "   'language': 'en'},\n",
       "  {'text': \" No, actually, I just came out to my parents' house to\",\n",
       "   'start': 184.672,\n",
       "   'end': 187.488,\n",
       "   'language': 'en'},\n",
       "  {'text': \" over their driveway and I'm headed back to my office.\",\n",
       "   'start': 187.712,\n",
       "   'end': 190.4,\n",
       "   'language': 'en'},\n",
       "  {'text': ' around there for awhile.',\n",
       "   'start': 192.96,\n",
       "   'end': 194.016,\n",
       "   'language': 'en'},\n",
       "  {'text': ' book.', 'start': 194.784, 'end': 194.976, 'language': 'en'},\n",
       "  {'text': ' What do you do?',\n",
       "   'start': 199.936,\n",
       "   'end': 200.352,\n",
       "   'language': 'en'},\n",
       "  {'text': ' key consultants.',\n",
       "   'start': 202.912,\n",
       "   'end': 203.616,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Gotcha.', 'start': 206.368, 'end': 206.656, 'language': 'en'},\n",
       "  {'text': ' a real estate broker.',\n",
       "   'start': 207.808,\n",
       "   'end': 208.736,\n",
       "   'language': 'en'},\n",
       "  {'text': ' So.', 'start': 210.208, 'end': 210.4, 'language': 'en'},\n",
       "  {'text': ' a slow day in the real estate business, but',\n",
       "   'start': 211.264,\n",
       "   'end': 213.376,\n",
       "   'language': 'en'},\n",
       "  {'text': ' a lot of', 'start': 214.4, 'end': 214.688, 'language': 'en'},\n",
       "  {'text': ' plenty of paperwork to do so.',\n",
       "   'start': 214.976,\n",
       "   'end': 216.096,\n",
       "   'language': 'en'},\n",
       "  {'text': ' 34.', 'start': 218.464, 'end': 219.328, 'language': 'en'},\n",
       "  {'text': ' yourself.', 'start': 221.408, 'end': 221.952, 'language': 'en'},\n",
       "  {'text': ' three minutes into this.',\n",
       "   'start': 230.336,\n",
       "   'end': 231.264,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Okay.', 'start': 235.072, 'end': 235.328, 'language': 'en'},\n",
       "  {'text': ' I think that,',\n",
       "   'start': 238.208,\n",
       "   'end': 238.688,\n",
       "   'language': 'en'},\n",
       "  {'text': ' That was probably simultaneous when they did the...',\n",
       "   'start': 240.0,\n",
       "   'end': 242.816,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Introduction.',\n",
       "   'start': 243.104,\n",
       "   'end': 243.776,\n",
       "   'language': 'en'},\n",
       "  {'text': ' So do you have any idea what',\n",
       "   'start': 247.424,\n",
       "   'end': 249.728,\n",
       "   'language': 'en'},\n",
       "  {'text': ' is behind this program. What are they doing?',\n",
       "   'start': 249.984,\n",
       "   'end': 251.648,\n",
       "   'language': 'en'},\n",
       "  {'text': \" we're kind of\",\n",
       "   'start': 251.808,\n",
       "   'end': 252.352,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 259.104, 'end': 259.136, 'language': 'en'},\n",
       "  {'text': ' Well, my friend works',\n",
       "   'start': 263.36,\n",
       "   'end': 265.12,\n",
       "   'language': 'en'},\n",
       "  {'text': ' for the government and he works at NIST.',\n",
       "   'start': 265.248,\n",
       "   'end': 266.72,\n",
       "   'language': 'en'},\n",
       "  {'text': \" and he's in the...\",\n",
       "   'start': 268.352,\n",
       "   'end': 269.344,\n",
       "   'language': 'en'},\n",
       "  {'text': ' automated speech recognition,',\n",
       "   'start': 269.792,\n",
       "   'end': 271.328,\n",
       "   'language': 'en'},\n",
       "  {'text': ' division.', 'start': 271.552, 'end': 272.064, 'language': 'en'},\n",
       "  {'text': ' I think.', 'start': 272.288, 'end': 272.64, 'language': 'en'},\n",
       "  {'text': ' That would make sense.',\n",
       "   'start': 275.264,\n",
       "   'end': 276.064,\n",
       "   'language': 'en'},\n",
       "  {'text': ' I should turn you on to this.',\n",
       "   'start': 280.384,\n",
       "   'end': 281.408,\n",
       "   'language': 'en'},\n",
       "  {'text': \" That's how you found out about the survey?\",\n",
       "   'start': 282.752,\n",
       "   'end': 284.32,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Okay.', 'start': 284.736, 'end': 284.896, 'language': 'en'},\n",
       "  {'text': \" What's your favorite restaurant in New York?\",\n",
       "   'start': 304.288,\n",
       "   'end': 305.792,\n",
       "   'language': 'en'},\n",
       "  {'text': ' your favorite type of food?',\n",
       "   'start': 309.056,\n",
       "   'end': 310.112,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Okay.', 'start': 322.144, 'end': 322.336, 'language': 'en'},\n",
       "  {'text': ' What?', 'start': 334.24, 'end': 334.56, 'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 335.744, 'end': 335.84, 'language': 'en'},\n",
       "  {'text': ' Wow.', 'start': 349.12, 'end': 349.44, 'language': 'en'},\n",
       "  {'text': ' Did you go to school?',\n",
       "   'start': 353.952,\n",
       "   'end': 354.624,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Did you go to school in New York?',\n",
       "   'start': 354.752,\n",
       "   'end': 355.776,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Well done.', 'start': 356.928, 'end': 357.216, 'language': 'en'},\n",
       "  {'text': ' Gotcha.', 'start': 359.584, 'end': 359.936, 'language': 'en'},\n",
       "  {'text': \" I went to Mount St. Mary's College.\",\n",
       "   'start': 361.568,\n",
       "   'end': 363.072,\n",
       "   'language': 'en'},\n",
       "  {'text': ' in Emmitsburg, Maryland.',\n",
       "   'start': 363.904,\n",
       "   'end': 364.992,\n",
       "   'language': 'en'},\n",
       "  {'text': ' you.', 'start': 366.304, 'end': 366.688, 'language': 'en'},\n",
       "  {'text': ' Yeah.', 'start': 368.16, 'end': 368.832, 'language': 'en'},\n",
       "  {'text': \" I've lived here all my life.\",\n",
       "   'start': 369.28,\n",
       "   'end': 370.368,\n",
       "   'language': 'en'},\n",
       "  {'text': ' in uh...', 'start': 370.592, 'end': 371.328, 'language': 'en'},\n",
       "  {'text': \" It's a nice state.\",\n",
       "   'start': 372.64,\n",
       "   'end': 374.176,\n",
       "   'language': 'en'},\n",
       "  {'text': \" New York's a fun place to come visit, my friend.\",\n",
       "   'start': 374.592,\n",
       "   'end': 376.544,\n",
       "   'language': 'en'},\n",
       "  {'text': ' who lives up there, I go up and see him every once in a while,',\n",
       "   'start': 377.12,\n",
       "   'end': 379.904,\n",
       "   'language': 'en'},\n",
       "  {'text': ' They could never live there.',\n",
       "   'start': 380.544,\n",
       "   'end': 381.472,\n",
       "   'language': 'en'},\n",
       "  {'text': \" He's,\", 'start': 381.664, 'end': 381.92, 'language': 'en'},\n",
       "  {'text': \" transplanted and sworn by it and says he'll never move\",\n",
       "   'start': 382.496,\n",
       "   'end': 385.504,\n",
       "   'language': 'en'},\n",
       "  {'text': \" And so it's nice to go visit and\",\n",
       "   'start': 386.528,\n",
       "   'end': 389.792,\n",
       "   'language': 'en'},\n",
       "  {'text': \" It's been a long weekend or just to see a show.\",\n",
       "   'start': 390.944,\n",
       "   'end': 393.792,\n",
       "   'language': 'en'},\n",
       "  {'text': ' I got to come home.',\n",
       "   'start': 394.784,\n",
       "   'end': 395.904,\n",
       "   'language': 'en'},\n",
       "  {'text': ' almost.', 'start': 401.376, 'end': 401.632, 'language': 'en'},\n",
       "  {'text': ' That happens.',\n",
       "   'start': 401.76,\n",
       "   'end': 402.272,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 410.752, 'end': 410.784, 'language': 'en'},\n",
       "  {'text': ' part of Jersey.',\n",
       "   'start': 416.8,\n",
       "   'end': 417.632,\n",
       "   'language': 'en'},\n",
       "  {'text': \" about everybody from Mount St. Mary's was from Jersey.\",\n",
       "   'start': 421.376,\n",
       "   'end': 423.168,\n",
       "   'language': 'en'},\n",
       "  {'text': \" Yeah, I think Jersey's\",\n",
       "   'start': 424.096,\n",
       "   'end': 424.992,\n",
       "   'language': 'en'},\n",
       "  {'text': \" Staple crop is college students, isn't it?\",\n",
       "   'start': 425.12,\n",
       "   'end': 426.912,\n",
       "   'language': 'en'},\n",
       "  {'text': \" It's like what\",\n",
       "   'start': 427.712,\n",
       "   'end': 428.288,\n",
       "   'language': 'en'},\n",
       "  {'text': \" the state produces most of it's college students.\",\n",
       "   'start': 428.544,\n",
       "   'end': 430.848,\n",
       "   'language': 'en'},\n",
       "  {'text': ' No, seriously, everybody from',\n",
       "   'start': 431.296,\n",
       "   'end': 432.672,\n",
       "   'language': 'en'},\n",
       "  {'text': ' just about everybody from them out was',\n",
       "   'start': 432.832,\n",
       "   'end': 434.592,\n",
       "   'language': 'en'},\n",
       "  {'text': ' New Jersey.', 'start': 435.072, 'end': 435.712, 'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 438.592, 'end': 438.912, 'language': 'en'},\n",
       "  {'text': \" That's...\", 'start': 439.104, 'end': 439.392, 'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 440.928, 'end': 441.472, 'language': 'en'},\n",
       "  {'text': \" Are there no colleges? Aren't there, like, is Rutgers?\",\n",
       "   'start': 443.2,\n",
       "   'end': 445.664,\n",
       "   'language': 'en'},\n",
       "  {'text': \" Rutgers is in Jersey, isn't it?\",\n",
       "   'start': 445.92,\n",
       "   'end': 447.04,\n",
       "   'language': 'en'},\n",
       "  {'text': \" That's it.\", 'start': 450.048, 'end': 450.4, 'language': 'en'},\n",
       "  {'text': ' Yeah.', 'start': 454.528, 'end': 454.816, 'language': 'en'},\n",
       "  {'text': ' Do you know my friend, Steve Lewis?',\n",
       "   'start': 462.336,\n",
       "   'end': 463.936,\n",
       "   'language': 'en'},\n",
       "  {'text': ' No.', 'start': 465.344, 'end': 465.696, 'language': 'en'},\n",
       "  {'text': ' Bye.', 'start': 466.688, 'end': 466.88, 'language': 'en'},\n",
       "  {'text': ' How about Shirley?',\n",
       "   'start': 467.232,\n",
       "   'end': 468.128,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Nice to have you.',\n",
       "   'start': 468.352,\n",
       "   'end': 469.12,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Shelby.', 'start': 469.248, 'end': 469.888, 'language': 'en'},\n",
       "  {'text': ' Lanham', 'start': 470.176, 'end': 470.656, 'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 470.816, 'end': 470.848, 'language': 'en'},\n",
       "  {'text': \" I don't,\", 'start': 471.232, 'end': 471.488, 'language': 'en'},\n",
       "  {'text': ' Everett.', 'start': 473.024, 'end': 473.312, 'language': 'en'},\n",
       "  {'text': \" They're both...\",\n",
       "   'start': 473.568,\n",
       "   'end': 474.304,\n",
       "   'language': 'en'},\n",
       "  {'text': ' They both work',\n",
       "   'start': 474.848,\n",
       "   'end': 475.296,\n",
       "   'language': 'en'},\n",
       "  {'text': ' reports.', 'start': 475.52, 'end': 476.064, 'language': 'en'},\n",
       "  {'text': ' a company called Fitz and Morrison Company.',\n",
       "   'start': 476.192,\n",
       "   'end': 477.888,\n",
       "   'language': 'en'},\n",
       "  {'text': ' and um,', 'start': 478.496, 'end': 479.552, 'language': 'en'},\n",
       "  {'text': ' they,', 'start': 480.736, 'end': 481.344, 'language': 'en'},\n",
       "  {'text': ' They actually just got engaged.',\n",
       "   'start': 481.568,\n",
       "   'end': 482.656,\n",
       "   'language': 'en'},\n",
       "  {'text': \" Shelby's from LA. She lives in New York.\",\n",
       "   'start': 482.912,\n",
       "   'end': 484.992,\n",
       "   'language': 'en'},\n",
       "  {'text': \" not sure where her place is and Steve's\",\n",
       "   'start': 485.888,\n",
       "   'end': 487.808,\n",
       "   'language': 'en'},\n",
       "  {'text': ' the one who lives at 87th and Columbus.',\n",
       "   'start': 488.16,\n",
       "   'end': 489.824,\n",
       "   'language': 'en'},\n",
       "  {'text': ' um,', 'start': 490.816, 'end': 491.232, 'language': 'en'},\n",
       "  {'text': \" I THINK WE'VE HAD A\",\n",
       "   'start': 492.928,\n",
       "   'end': 493.6,\n",
       "   'language': 'en'},\n",
       "  {'text': \" They met through work. They're actually getting married next summer in L.A. That's where she's from.\",\n",
       "   'start': 496.416,\n",
       "   'end': 500.64,\n",
       "   'language': 'en'},\n",
       "  {'text': ' but, um,', 'start': 501.792, 'end': 502.592, 'language': 'en'},\n",
       "  {'text': \" it's insurance\",\n",
       "   'start': 503.424,\n",
       "   'end': 504.704,\n",
       "   'language': 'en'},\n",
       "  {'text': ' corporate insurance, basically.',\n",
       "   'start': 506.112,\n",
       "   'end': 507.36,\n",
       "   'language': 'en'},\n",
       "  {'text': \" That's their...\",\n",
       "   'start': 508.384,\n",
       "   'end': 509.088,\n",
       "   'language': 'en'},\n",
       "  {'text': ' what they focus on, like they do',\n",
       "   'start': 509.28,\n",
       "   'end': 510.848,\n",
       "   'language': 'en'},\n",
       "  {'text': ' How do I know them?',\n",
       "   'start': 511.872,\n",
       "   'end': 512.576,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Steve and I went to high school together.',\n",
       "   'start': 513.472,\n",
       "   'end': 514.592,\n",
       "   'language': 'en'},\n",
       "  {'text': \" So I've known him since high school.\",\n",
       "   'start': 515.808,\n",
       "   'end': 517.728,\n",
       "   'language': 'en'},\n",
       "  {'text': ' stayed friends through college. He went to Villanova.',\n",
       "   'start': 518.56,\n",
       "   'end': 520.544,\n",
       "   'language': 'en'},\n",
       "  {'text': ' and', 'start': 521.056, 'end': 521.568, 'language': 'en'},\n",
       "  {'text': ' And we just...',\n",
       "   'start': 522.88,\n",
       "   'end': 523.296,\n",
       "   'language': 'en'},\n",
       "  {'text': ' all these states',\n",
       "   'start': 523.584,\n",
       "   'end': 524.032,\n",
       "   'language': 'en'},\n",
       "  {'text': ' So.', 'start': 524.16, 'end': 524.704, 'language': 'en'},\n",
       "  {'text': ' about it.', 'start': 526.496, 'end': 527.36, 'language': 'en'},\n",
       "  {'text': \" No, and I can't wait.\",\n",
       "   'start': 528.8,\n",
       "   'end': 529.984,\n",
       "   'language': 'en'},\n",
       "  {'text': \" because we're going to go out for their wedding next summer and, uh,\",\n",
       "   'start': 530.304,\n",
       "   'end': 532.864,\n",
       "   'language': 'en'},\n",
       "  {'text': ' probably.', 'start': 533.344, 'end': 533.568, 'language': 'en'},\n",
       "  {'text': ' take a couple of weeks and do a West Coast tour.',\n",
       "   'start': 533.792,\n",
       "   'end': 536.096,\n",
       "   'language': 'en'},\n",
       "  {'text': ' And, um,', 'start': 536.928, 'end': 537.728, 'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 538.4, 'end': 538.528, 'language': 'en'},\n",
       "  {'text': \" I've been to San Francisco, but I've never been.\",\n",
       "   'start': 540.672,\n",
       "   'end': 542.912,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Anywhere other than',\n",
       "   'start': 543.808,\n",
       "   'end': 544.608,\n",
       "   'language': 'en'},\n",
       "  {'text': ' San Francisco area, the Bay area.',\n",
       "   'start': 544.8,\n",
       "   'end': 546.912,\n",
       "   'language': 'en'},\n",
       "  {'text': \" And that was years ago. I don't even remember it.\",\n",
       "   'start': 547.424,\n",
       "   'end': 549.568,\n",
       "   'language': 'en'},\n",
       "  {'text': ' looking forward to it.',\n",
       "   'start': 550.304,\n",
       "   'end': 551.392,\n",
       "   'language': 'en'},\n",
       "  {'text': ' What I remember.',\n",
       "   'start': 554.336,\n",
       "   'end': 555.072,\n",
       "   'language': 'en'},\n",
       "  {'text': ' from what I remember, it was there for a wedding.',\n",
       "   'start': 555.328,\n",
       "   'end': 556.8,\n",
       "   'language': 'en'},\n",
       "  {'text': ' as well.', 'start': 557.088, 'end': 557.792, 'language': 'en'},\n",
       "  {'text': ' Thank you.', 'start': 557.984, 'end': 558.176, 'language': 'en'},\n",
       "  {'text': ' Okay.', 'start': 562.656, 'end': 562.848, 'language': 'en'},\n",
       "  {'text': ' Well...', 'start': 563.104, 'end': 563.2, 'language': 'en'},\n",
       "  {'text': ' happens now.',\n",
       "   'start': 565.952,\n",
       "   'end': 566.848,\n",
       "   'language': 'en'},\n",
       "  {'text': ' This is not at all.',\n",
       "   'start': 571.68,\n",
       "   'end': 573.408,\n",
       "   'language': 'en'},\n",
       "  {'text': ' had no idea what to expect but this',\n",
       "   'start': 573.92,\n",
       "   'end': 575.456,\n",
       "   'language': 'en'},\n",
       "  {'text': ' certainly not what I expected that we would',\n",
       "   'start': 575.584,\n",
       "   'end': 577.312,\n",
       "   'language': 'en'},\n",
       "  {'text': ' just get into a dialogue with a stranger and talk about whatever.',\n",
       "   'start': 577.888,\n",
       "   'end': 580.8,\n",
       "   'language': 'en'},\n",
       "  {'text': ' but the topic, excuse me,',\n",
       "   'start': 581.312,\n",
       "   'end': 582.72,\n",
       "   'language': 'en'},\n",
       "  {'text': ' restaurants and food.',\n",
       "   'start': 582.976,\n",
       "   'end': 584.064,\n",
       "   'language': 'en'},\n",
       "  {'text': ' And, um,', 'start': 584.64, 'end': 585.44, 'language': 'en'},\n",
       "  {'text': ' No, I thought that they would have',\n",
       "   'start': 586.176,\n",
       "   'end': 587.552,\n",
       "   'language': 'en'},\n",
       "  {'text': ' a computer or something running the',\n",
       "   'start': 589.728,\n",
       "   'end': 592.352,\n",
       "   'language': 'en'},\n",
       "  {'text': ' the talk but',\n",
       "   'start': 593.376,\n",
       "   'end': 594.144,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Oh, well.', 'start': 595.168, 'end': 595.84, 'language': 'en'},\n",
       "  {'text': ' I guess...', 'start': 596.064, 'end': 597.184, 'language': 'en'},\n",
       "  {'text': \" That's probably it then if we've talked for 10 minutes.\",\n",
       "   'start': 597.44,\n",
       "   'end': 599.552,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Enjoy the rest of your day and enjoy the snow.',\n",
       "   'start': 599.968,\n",
       "   'end': 602.048,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Nice chatting with you.',\n",
       "   'start': 602.88,\n",
       "   'end': 603.712,\n",
       "   'language': 'en'},\n",
       "  {'text': ' Take care. Bye.',\n",
       "   'start': 604.16,\n",
       "   'end': 604.928,\n",
       "   'language': 'en'}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ' Hello, my name is Tony Chiquilla.', 'start': 0.768, 'end': 3.136},\n",
       " {'text': ' and', 'start': 3.808, 'end': 4.288},\n",
       " {'text': ' I generally prefer.', 'start': 4.416, 'end': 5.568},\n",
       " {'text': ' eating at home.', 'start': 5.856, 'end': 6.496},\n",
       " {'text': ' Hello Andy.', 'start': 10.144, 'end': 10.88},\n",
       " {'text': ' How are you?', 'start': 11.904, 'end': 12.288},\n",
       " {'text': ' Good.', 'start': 13.664, 'end': 13.952},\n",
       " {'text': \" You have any idea what's going on?\",\n",
       "  'start': 14.528,\n",
       "  'end': 15.712},\n",
       " {'text': ' Yeah.', 'start': 19.136, 'end': 19.488},\n",
       " {'text': \" What's your preference?\", 'start': 20.256, 'end': 21.216},\n",
       " {'text': ' Thank you.', 'start': 24.672, 'end': 24.896},\n",
       " {'text': \" I'm eating at home\", 'start': 31.744, 'end': 32.512},\n",
       " {'text': ' Uh,', 'start': 34.976, 'end': 35.072},\n",
       " {'text': ' um,', 'start': 35.392, 'end': 35.584},\n",
       " {'text': ' No.', 'start': 37.376, 'end': 37.728},\n",
       " {'text': ' uh...', 'start': 37.888, 'end': 38.624},\n",
       " {'text': ' enjoy eating at home better than', 'start': 38.784, 'end': 40.416},\n",
       " {'text': ' mean casual.', 'start': 40.8, 'end': 41.568},\n",
       " {'text': ' Periodic dining out is fine,', 'start': 42.304, 'end': 43.968},\n",
       " {'text': ' generally speaking, like eating at home.',\n",
       "  'start': 44.48,\n",
       "  'end': 45.952},\n",
       " {'text': ' Wow.', 'start': 51.776, 'end': 52.128},\n",
       " {'text': ' Well, that makes a difference.', 'start': 54.592, 'end': 55.52},\n",
       " {'text': ' Yeah.', 'start': 56.32, 'end': 56.832},\n",
       " {'text': ' I live in Frederick, Maryland.', 'start': 58.304, 'end': 60.032},\n",
       " {'text': ' a lot.', 'start': 61.504, 'end': 61.856},\n",
       " {'text': ' smaller town.', 'start': 62.432, 'end': 63.104},\n",
       " {'text': ' Yes.', 'start': 63.392, 'end': 63.776},\n",
       " {'text': ' think that was it.', 'start': 67.776, 'end': 68.384},\n",
       " {'text': ' Yeah.', 'start': 69.568, 'end': 69.792},\n",
       " {'text': ' I think it was.', 'start': 71.008, 'end': 71.552},\n",
       " {'text': ' Yeah, I think that was the only question.',\n",
       "  'start': 72.0,\n",
       "  'end': 73.344},\n",
       " {'text': \" Is this the first time you've gotten one of these calls?\",\n",
       "  'start': 74.24,\n",
       "  'end': 76.288},\n",
       " {'text': ' Yeah, likewise.', 'start': 77.024, 'end': 77.792},\n",
       " {'text': ' Yes.', 'start': 77.952, 'end': 78.272},\n",
       " {'text': \" Likewise, I have a friend who's\", 'start': 82.528, 'end': 84.32},\n",
       " {'text': ' who turned me on to this, who works for NIST.',\n",
       "  'start': 84.928,\n",
       "  'end': 87.296},\n",
       " {'text': ' Thank you.', 'start': 87.424, 'end': 87.488},\n",
       " {'text': ' sent me an email about it.', 'start': 88.096, 'end': 88.992},\n",
       " {'text': \" I guess he's working on some of the programming behind this,\",\n",
       "  'start': 89.344,\n",
       "  'end': 91.712},\n",
       " {'text': ' Gotcha.', 'start': 100.0, 'end': 100.352},\n",
       " {'text': ' Okay.', 'start': 103.04, 'end': 103.648},\n",
       " {'text': ' So now what happens?', 'start': 103.808, 'end': 104.672},\n",
       " {'text': \" We stopped talking. They'll come back online.\",\n",
       "  'start': 110.176,\n",
       "  'end': 111.808},\n",
       " {'text': \" We're supposed to talk for 10 minutes.\",\n",
       "  'start': 114.272,\n",
       "  'end': 115.488},\n",
       " {'text': ' Yeah, I did read something about 10 minutes.',\n",
       "  'start': 118.624,\n",
       "  'end': 120.992},\n",
       " {'text': ' Is it snowing up there?', 'start': 127.328, 'end': 128.48},\n",
       " {'text': ' Thank you.', 'start': 128.672, 'end': 128.704},\n",
       " {'text': ' Likewise.', 'start': 130.656, 'end': 131.04},\n",
       " {'text': ' Where are you in New York?', 'start': 131.168, 'end': 131.968},\n",
       " {'text': ' in Manhattan.', 'start': 133.44, 'end': 134.016},\n",
       " {'text': ' of my best friends lives on the',\n",
       "  'start': 135.104,\n",
       "  'end': 136.224},\n",
       " {'text': ' Upper West Side at 87th and Columbus.',\n",
       "  'start': 136.8,\n",
       "  'end': 138.72},\n",
       " {'text': ' right in the neighborhood.', 'start': 141.536, 'end': 142.176},\n",
       " {'text': \" I think it's the Jackson Hole.\", 'start': 142.816, 'end': 144.8},\n",
       " {'text': \" That's right on the\", 'start': 146.592, 'end': 147.232},\n",
       " {'text': \" Yeah, it's right on the first floor of the building he's in.\",\n",
       "  'start': 148.0,\n",
       "  'end': 150.272},\n",
       " {'text': ' Mm-hmm.', 'start': 151.968, 'end': 152.256},\n",
       " {'text': ' Yep.', 'start': 152.896, 'end': 153.056},\n",
       " {'text': ' any times.', 'start': 153.568, 'end': 154.176},\n",
       " {'text': ' um,', 'start': 156.896, 'end': 157.216},\n",
       " {'text': ' Frederick, Maryland, where an hour',\n",
       "  'start': 157.408,\n",
       "  'end': 158.72},\n",
       " {'text': ' north of Washington, D.C.,', 'start': 158.976, 'end': 160.832},\n",
       " {'text': ' in about an hour.', 'start': 162.016, 'end': 163.36},\n",
       " {'text': ' west of Baltimore.', 'start': 163.488, 'end': 164.544},\n",
       " {'text': ' So.', 'start': 166.656, 'end': 167.008},\n",
       " {'text': \" and it's snowing here, we have about\",\n",
       "  'start': 167.872,\n",
       "  'end': 169.376},\n",
       " {'text': ' eight inches, eight to 10 inches of snow.',\n",
       "  'start': 169.952,\n",
       "  'end': 171.808},\n",
       " {'text': ' Yeah.', 'start': 181.056, 'end': 181.312},\n",
       " {'text': \" like we're...\", 'start': 181.44, 'end': 181.856},\n",
       " {'text': ' in that neighborhood too.', 'start': 182.016, 'end': 183.072},\n",
       " {'text': \" No, actually, I just came out to my parents' house to\",\n",
       "  'start': 184.672,\n",
       "  'end': 187.488},\n",
       " {'text': \" over their driveway and I'm headed back to my office.\",\n",
       "  'start': 187.712,\n",
       "  'end': 190.4},\n",
       " {'text': ' around there for awhile.', 'start': 192.96, 'end': 194.016},\n",
       " {'text': ' book.', 'start': 194.784, 'end': 194.976},\n",
       " {'text': ' What do you do?', 'start': 199.936, 'end': 200.352},\n",
       " {'text': ' key consultants.', 'start': 202.912, 'end': 203.616},\n",
       " {'text': ' Gotcha.', 'start': 206.368, 'end': 206.656},\n",
       " {'text': ' a real estate broker.', 'start': 207.808, 'end': 208.736},\n",
       " {'text': ' So.', 'start': 210.208, 'end': 210.4},\n",
       " {'text': ' a slow day in the real estate business, but',\n",
       "  'start': 211.264,\n",
       "  'end': 213.376},\n",
       " {'text': ' a lot of', 'start': 214.4, 'end': 214.688},\n",
       " {'text': ' plenty of paperwork to do so.', 'start': 214.976, 'end': 216.096},\n",
       " {'text': ' 34.', 'start': 218.464, 'end': 219.328},\n",
       " {'text': ' yourself.', 'start': 221.408, 'end': 221.952},\n",
       " {'text': ' three minutes into this.', 'start': 230.336, 'end': 231.264},\n",
       " {'text': ' Okay.', 'start': 235.072, 'end': 235.328},\n",
       " {'text': ' I think that,', 'start': 238.208, 'end': 238.688},\n",
       " {'text': ' That was probably simultaneous when they did the...',\n",
       "  'start': 240.0,\n",
       "  'end': 242.816},\n",
       " {'text': ' Introduction.', 'start': 243.104, 'end': 243.776},\n",
       " {'text': ' So do you have any idea what', 'start': 247.424, 'end': 249.728},\n",
       " {'text': ' is behind this program. What are they doing?',\n",
       "  'start': 249.984,\n",
       "  'end': 251.648},\n",
       " {'text': \" we're kind of\", 'start': 251.808, 'end': 252.352},\n",
       " {'text': ' Thank you.', 'start': 259.104, 'end': 259.136},\n",
       " {'text': ' Well, my friend works', 'start': 263.36, 'end': 265.12},\n",
       " {'text': ' for the government and he works at NIST.',\n",
       "  'start': 265.248,\n",
       "  'end': 266.72},\n",
       " {'text': \" and he's in the...\", 'start': 268.352, 'end': 269.344},\n",
       " {'text': ' automated speech recognition,', 'start': 269.792, 'end': 271.328},\n",
       " {'text': ' division.', 'start': 271.552, 'end': 272.064},\n",
       " {'text': ' I think.', 'start': 272.288, 'end': 272.64},\n",
       " {'text': ' That would make sense.', 'start': 275.264, 'end': 276.064},\n",
       " {'text': ' I should turn you on to this.', 'start': 280.384, 'end': 281.408},\n",
       " {'text': \" That's how you found out about the survey?\",\n",
       "  'start': 282.752,\n",
       "  'end': 284.32},\n",
       " {'text': ' Okay.', 'start': 284.736, 'end': 284.896},\n",
       " {'text': \" What's your favorite restaurant in New York?\",\n",
       "  'start': 304.288,\n",
       "  'end': 305.792},\n",
       " {'text': ' your favorite type of food?', 'start': 309.056, 'end': 310.112},\n",
       " {'text': ' Okay.', 'start': 322.144, 'end': 322.336},\n",
       " {'text': ' What?', 'start': 334.24, 'end': 334.56},\n",
       " {'text': ' Thank you.', 'start': 335.744, 'end': 335.84},\n",
       " {'text': ' Wow.', 'start': 349.12, 'end': 349.44},\n",
       " {'text': ' Did you go to school?', 'start': 353.952, 'end': 354.624},\n",
       " {'text': ' Did you go to school in New York?',\n",
       "  'start': 354.752,\n",
       "  'end': 355.776},\n",
       " {'text': ' Well done.', 'start': 356.928, 'end': 357.216},\n",
       " {'text': ' Gotcha.', 'start': 359.584, 'end': 359.936},\n",
       " {'text': \" I went to Mount St. Mary's College.\",\n",
       "  'start': 361.568,\n",
       "  'end': 363.072},\n",
       " {'text': ' in Emmitsburg, Maryland.', 'start': 363.904, 'end': 364.992},\n",
       " {'text': ' you.', 'start': 366.304, 'end': 366.688},\n",
       " {'text': ' Yeah.', 'start': 368.16, 'end': 368.832},\n",
       " {'text': \" I've lived here all my life.\", 'start': 369.28, 'end': 370.368},\n",
       " {'text': ' in uh...', 'start': 370.592, 'end': 371.328},\n",
       " {'text': \" It's a nice state.\", 'start': 372.64, 'end': 374.176},\n",
       " {'text': \" New York's a fun place to come visit, my friend.\",\n",
       "  'start': 374.592,\n",
       "  'end': 376.544},\n",
       " {'text': ' who lives up there, I go up and see him every once in a while,',\n",
       "  'start': 377.12,\n",
       "  'end': 379.904},\n",
       " {'text': ' They could never live there.', 'start': 380.544, 'end': 381.472},\n",
       " {'text': \" He's,\", 'start': 381.664, 'end': 381.92},\n",
       " {'text': \" transplanted and sworn by it and says he'll never move\",\n",
       "  'start': 382.496,\n",
       "  'end': 385.504},\n",
       " {'text': \" And so it's nice to go visit and\",\n",
       "  'start': 386.528,\n",
       "  'end': 389.792},\n",
       " {'text': \" It's been a long weekend or just to see a show.\",\n",
       "  'start': 390.944,\n",
       "  'end': 393.792},\n",
       " {'text': ' I got to come home.', 'start': 394.784, 'end': 395.904},\n",
       " {'text': ' almost.', 'start': 401.376, 'end': 401.632},\n",
       " {'text': ' That happens.', 'start': 401.76, 'end': 402.272},\n",
       " {'text': ' Thank you.', 'start': 410.752, 'end': 410.784},\n",
       " {'text': ' part of Jersey.', 'start': 416.8, 'end': 417.632},\n",
       " {'text': \" about everybody from Mount St. Mary's was from Jersey.\",\n",
       "  'start': 421.376,\n",
       "  'end': 423.168},\n",
       " {'text': \" Yeah, I think Jersey's\", 'start': 424.096, 'end': 424.992},\n",
       " {'text': \" Staple crop is college students, isn't it?\",\n",
       "  'start': 425.12,\n",
       "  'end': 426.912},\n",
       " {'text': \" It's like what\", 'start': 427.712, 'end': 428.288},\n",
       " {'text': \" the state produces most of it's college students.\",\n",
       "  'start': 428.544,\n",
       "  'end': 430.848},\n",
       " {'text': ' No, seriously, everybody from', 'start': 431.296, 'end': 432.672},\n",
       " {'text': ' just about everybody from them out was',\n",
       "  'start': 432.832,\n",
       "  'end': 434.592},\n",
       " {'text': ' New Jersey.', 'start': 435.072, 'end': 435.712},\n",
       " {'text': ' Thank you.', 'start': 438.592, 'end': 438.912},\n",
       " {'text': \" That's...\", 'start': 439.104, 'end': 439.392},\n",
       " {'text': ' Thank you.', 'start': 440.928, 'end': 441.472},\n",
       " {'text': \" Are there no colleges? Aren't there, like, is Rutgers?\",\n",
       "  'start': 443.2,\n",
       "  'end': 445.664},\n",
       " {'text': \" Rutgers is in Jersey, isn't it?\", 'start': 445.92, 'end': 447.04},\n",
       " {'text': \" That's it.\", 'start': 450.048, 'end': 450.4},\n",
       " {'text': ' Yeah.', 'start': 454.528, 'end': 454.816},\n",
       " {'text': ' Do you know my friend, Steve Lewis?',\n",
       "  'start': 462.336,\n",
       "  'end': 463.936},\n",
       " {'text': ' No.', 'start': 465.344, 'end': 465.696},\n",
       " {'text': ' Bye.', 'start': 466.688, 'end': 466.88},\n",
       " {'text': ' How about Shirley?', 'start': 467.232, 'end': 468.128},\n",
       " {'text': ' Nice to have you.', 'start': 468.352, 'end': 469.12},\n",
       " {'text': ' Shelby.', 'start': 469.248, 'end': 469.888},\n",
       " {'text': ' Lanham', 'start': 470.176, 'end': 470.656},\n",
       " {'text': ' Thank you.', 'start': 470.816, 'end': 470.848},\n",
       " {'text': \" I don't,\", 'start': 471.232, 'end': 471.488},\n",
       " {'text': ' Everett.', 'start': 473.024, 'end': 473.312},\n",
       " {'text': \" They're both...\", 'start': 473.568, 'end': 474.304},\n",
       " {'text': ' They both work', 'start': 474.848, 'end': 475.296},\n",
       " {'text': ' reports.', 'start': 475.52, 'end': 476.064},\n",
       " {'text': ' a company called Fitz and Morrison Company.',\n",
       "  'start': 476.192,\n",
       "  'end': 477.888},\n",
       " {'text': ' and um,', 'start': 478.496, 'end': 479.552},\n",
       " {'text': ' they,', 'start': 480.736, 'end': 481.344},\n",
       " {'text': ' They actually just got engaged.',\n",
       "  'start': 481.568,\n",
       "  'end': 482.656},\n",
       " {'text': \" Shelby's from LA. She lives in New York.\",\n",
       "  'start': 482.912,\n",
       "  'end': 484.992},\n",
       " {'text': \" not sure where her place is and Steve's\",\n",
       "  'start': 485.888,\n",
       "  'end': 487.808},\n",
       " {'text': ' the one who lives at 87th and Columbus.',\n",
       "  'start': 488.16,\n",
       "  'end': 489.824},\n",
       " {'text': ' um,', 'start': 490.816, 'end': 491.232},\n",
       " {'text': \" I THINK WE'VE HAD A\", 'start': 492.928, 'end': 493.6},\n",
       " {'text': \" They met through work. They're actually getting married next summer in L.A. That's where she's from.\",\n",
       "  'start': 496.416,\n",
       "  'end': 500.64},\n",
       " {'text': ' but, um,', 'start': 501.792, 'end': 502.592},\n",
       " {'text': \" it's insurance\", 'start': 503.424, 'end': 504.704},\n",
       " {'text': ' corporate insurance, basically.', 'start': 506.112, 'end': 507.36},\n",
       " {'text': \" That's their...\", 'start': 508.384, 'end': 509.088},\n",
       " {'text': ' what they focus on, like they do',\n",
       "  'start': 509.28,\n",
       "  'end': 510.848},\n",
       " {'text': ' How do I know them?', 'start': 511.872, 'end': 512.576},\n",
       " {'text': ' Steve and I went to high school together.',\n",
       "  'start': 513.472,\n",
       "  'end': 514.592},\n",
       " {'text': \" So I've known him since high school.\",\n",
       "  'start': 515.808,\n",
       "  'end': 517.728},\n",
       " {'text': ' stayed friends through college. He went to Villanova.',\n",
       "  'start': 518.56,\n",
       "  'end': 520.544},\n",
       " {'text': ' and', 'start': 521.056, 'end': 521.568},\n",
       " {'text': ' And we just...', 'start': 522.88, 'end': 523.296},\n",
       " {'text': ' all these states', 'start': 523.584, 'end': 524.032},\n",
       " {'text': ' So.', 'start': 524.16, 'end': 524.704},\n",
       " {'text': ' about it.', 'start': 526.496, 'end': 527.36},\n",
       " {'text': \" No, and I can't wait.\", 'start': 528.8, 'end': 529.984},\n",
       " {'text': \" because we're going to go out for their wedding next summer and, uh,\",\n",
       "  'start': 530.304,\n",
       "  'end': 532.864},\n",
       " {'text': ' probably.', 'start': 533.344, 'end': 533.568},\n",
       " {'text': ' take a couple of weeks and do a West Coast tour.',\n",
       "  'start': 533.792,\n",
       "  'end': 536.096},\n",
       " {'text': ' And, um,', 'start': 536.928, 'end': 537.728},\n",
       " {'text': ' Thank you.', 'start': 538.4, 'end': 538.528},\n",
       " {'text': \" I've been to San Francisco, but I've never been.\",\n",
       "  'start': 540.672,\n",
       "  'end': 542.912},\n",
       " {'text': ' Anywhere other than', 'start': 543.808, 'end': 544.608},\n",
       " {'text': ' San Francisco area, the Bay area.',\n",
       "  'start': 544.8,\n",
       "  'end': 546.912},\n",
       " {'text': \" And that was years ago. I don't even remember it.\",\n",
       "  'start': 547.424,\n",
       "  'end': 549.568},\n",
       " {'text': ' looking forward to it.', 'start': 550.304, 'end': 551.392},\n",
       " {'text': ' What I remember.', 'start': 554.336, 'end': 555.072},\n",
       " {'text': ' from what I remember, it was there for a wedding.',\n",
       "  'start': 555.328,\n",
       "  'end': 556.8},\n",
       " {'text': ' as well.', 'start': 557.088, 'end': 557.792},\n",
       " {'text': ' Thank you.', 'start': 557.984, 'end': 558.176},\n",
       " {'text': ' Okay.', 'start': 562.656, 'end': 562.848},\n",
       " {'text': ' Well...', 'start': 563.104, 'end': 563.2},\n",
       " {'text': ' happens now.', 'start': 565.952, 'end': 566.848},\n",
       " {'text': ' This is not at all.', 'start': 571.68, 'end': 573.408},\n",
       " {'text': ' had no idea what to expect but this',\n",
       "  'start': 573.92,\n",
       "  'end': 575.456},\n",
       " {'text': ' certainly not what I expected that we would',\n",
       "  'start': 575.584,\n",
       "  'end': 577.312},\n",
       " {'text': ' just get into a dialogue with a stranger and talk about whatever.',\n",
       "  'start': 577.888,\n",
       "  'end': 580.8},\n",
       " {'text': ' but the topic, excuse me,', 'start': 581.312, 'end': 582.72},\n",
       " {'text': ' restaurants and food.', 'start': 582.976, 'end': 584.064},\n",
       " {'text': ' And, um,', 'start': 584.64, 'end': 585.44},\n",
       " {'text': ' No, I thought that they would have',\n",
       "  'start': 586.176,\n",
       "  'end': 587.552},\n",
       " {'text': ' a computer or something running the',\n",
       "  'start': 589.728,\n",
       "  'end': 592.352},\n",
       " {'text': ' the talk but', 'start': 593.376, 'end': 594.144},\n",
       " {'text': ' Oh, well.', 'start': 595.168, 'end': 595.84},\n",
       " {'text': ' I guess...', 'start': 596.064, 'end': 597.184},\n",
       " {'text': \" That's probably it then if we've talked for 10 minutes.\",\n",
       "  'start': 597.44,\n",
       "  'end': 599.552},\n",
       " {'text': ' Enjoy the rest of your day and enjoy the snow.',\n",
       "  'start': 599.968,\n",
       "  'end': 602.048},\n",
       " {'text': ' Nice chatting with you.', 'start': 602.88, 'end': 603.712},\n",
       " {'text': ' Take care. Bye.', 'start': 604.16, 'end': 604.928}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the key with the maximum length list\n",
    "data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n",
    "max_key = max(data.keys(), key=lambda k: len(data[k]))\n",
    "max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio =\"examples/english_long_ch1.wav\"\n",
    "# audio =\"examples/hindi.wav\"\n",
    "\n",
    "batch_size=4\n",
    "chunk_size=chunk_size\n",
    "print_progress=print_progress\n",
    "verbose=verbose\n",
    "num_workers=0\n",
    "language=None\n",
    "task = \"transcribe\"\n",
    "print_progress=True\n",
    "combined_progress=True\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(audio, segments):\n",
    "    for seg in segments:\n",
    "        f1 = int(seg['start'] * SAMPLE_RATE)\n",
    "        f2 = int(seg['end'] * SAMPLE_RATE)\n",
    "        # print(f2-f1)\n",
    "        yield {'inputs': audio[f1:f2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(audio, str):\n",
    "    audio = load_audio(audio)\n",
    "            \n",
    "if issubclass(type(model.vad_model), Vad):\n",
    "    waveform = model.vad_model.preprocess_audio(audio)\n",
    "    merge_chunks =  model.vad_model.merge_chunks\n",
    "else:\n",
    "    waveform = Pyannote.preprocess_audio(audio)\n",
    "    merge_chunks = Pyannote.merge_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_segments = model.vad_model({\"waveform\": waveform, \"sample_rate\": SAMPLE_RATE})\n",
    "vad_segments = merge_chunks(\n",
    "    vad_segments,\n",
    "    chunk_size,\n",
    "    onset=model._vad_params[\"vad_onset\"],\n",
    "    offset=model._vad_params[\"vad_offset\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:04<00:00, 13.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "# First merge segments separated by just 1 second\n",
    "merged_segments = []\n",
    "current_segment = None\n",
    "X = 2  # Merge threshold in seconds\n",
    "\n",
    "for idx, seg in enumerate(vad_segments):\n",
    "    if current_segment is None:\n",
    "        current_segment = {\n",
    "            'start': seg['start'],\n",
    "            'end': seg['end'],\n",
    "            'original_segments': [seg]\n",
    "        }\n",
    "    else:\n",
    "        # If gap is less than X seconds\n",
    "        if seg['start'] - current_segment['end'] <= X:\n",
    "            # Merge by extending end time\n",
    "            current_segment['end'] = seg['end']\n",
    "            current_segment['original_segments'].append(seg)\n",
    "        else:\n",
    "            # Add current segment to merged list and start a new one\n",
    "            merged_segments.append(current_segment)\n",
    "            current_segment = {\n",
    "                'start': seg['start'],\n",
    "                'end': seg['end'],\n",
    "                'original_segments': [seg]\n",
    "            }\n",
    "\n",
    "# Add the last segment if it exists\n",
    "if current_segment is not None:\n",
    "    merged_segments.append(current_segment)\n",
    "\n",
    "# Detect language for each merged segment and assign to original segments\n",
    "language_segments = {}\n",
    "for merged_seg in tqdm(merged_segments):\n",
    "    # Extract audio for merged segment\n",
    "    f1 = int(merged_seg['start'] * SAMPLE_RATE)\n",
    "    f2 = int(merged_seg['end'] * SAMPLE_RATE)\n",
    "    segment_audio = audio[f1:f2]\n",
    "    \n",
    "    # Detect language for this merged segment\n",
    "    segment_language = model.detect_language(segment_audio)\n",
    "    \n",
    "    # Assign language to all original segments in this merged segment\n",
    "    for original_seg in merged_seg['original_segments']:\n",
    "        if segment_language not in language_segments:\n",
    "            language_segments[segment_language] = []\n",
    "        \n",
    "        language_segments[segment_language].append(original_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.tokenizer is None:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.tokenizer is None:\n",
    "    language = language or model.detect_language(audio)\n",
    "    task = task or \"transcribe\"\n",
    "    model.tokenizer = Tokenizer(\n",
    "        model.model.hf_tokenizer,\n",
    "        model.model.model.is_multilingual,\n",
    "        task=task,\n",
    "        language=language,\n",
    "    )\n",
    "else:\n",
    "    language = language or model.tokenizer.language_code\n",
    "    task = task or model.tokenizer.task\n",
    "    if task != model.tokenizer.task or language != model.tokenizer.language_code:\n",
    "        model.tokenizer = Tokenizer(\n",
    "            model.model.hf_tokenizer,\n",
    "            model.model.model.is_multilingual,\n",
    "            task=task,\n",
    "            language=language,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.suppress_numerals:\n",
    "    previous_suppress_tokens = model.options.suppress_tokens\n",
    "    numeral_symbol_tokens = find_numeral_symbol_tokens(model.tokenizer)\n",
    "    print(f\"Suppressing numeral and symbol tokens\")\n",
    "    new_suppressed_tokens = numeral_symbol_tokens + model.options.suppress_tokens\n",
    "    new_suppressed_tokens = list(set(new_suppressed_tokens))\n",
    "    model.options = replace(model.options, suppress_tokens=new_suppressed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments: List[SingleSegment] = []\n",
    "batch_size = batch_size or model._batch_size\n",
    "total_segments = len(vad_segments)\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218it [00:29,  7.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "for idx, out in tqdm(enumerate(model.__call__(data(audio, vad_segments), batch_size=batch_size, num_workers=num_workers))):\n",
    "    if print_progress:\n",
    "        base_progress = ((idx + 1) / total_segments) * 100\n",
    "        percent_complete = base_progress / 2 if combined_progress else base_progress\n",
    "        # print(f\"Progress: {percent_complete:.2f}%...\")\n",
    "    text = out['text']\n",
    "    if batch_size in [0, 1, None]:\n",
    "        text = text[0]\n",
    "    if False:\n",
    "        print(f\"Transcript: [{round(vad_segments[idx]['start'], 3)} --> {round(vad_segments[idx]['end'], 3)}] {text}\")\n",
    "    segments.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"start\": round(vad_segments[idx]['start'], 3),\n",
    "            \"end\": round(vad_segments[idx]['end'], 3)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msegments\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'segments' is not defined"
     ]
    }
   ],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m model.__call__(inputs, *args, num_workers=\u001b[38;5;28;01mNone\u001b[39;00m, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs)\n",
      "\u001b[31mDocstring:\u001b[39m Call self as a function.\n",
      "\u001b[31mSource:\u001b[39m   \n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, inputs, *args, num_workers=\u001b[38;5;28;01mNone\u001b[39;00m, batch_size=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m args:\n",
      "            logger.warning(f\"Ignoring args : {args}\")\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m num_workers \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m self._num_workers \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                num_workers = \u001b[32m0\u001b[39m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                num_workers = self._num_workers\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m self._batch_size \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                batch_size = \u001b[32m1\u001b[39m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                batch_size = self._batch_size\n",
      "\n",
      "        preprocess_params, forward_params, postprocess_params = self._sanitize_parameters(**kwargs)\n",
      "\n",
      "        \u001b[38;5;66;03m# Fuse __init__ params and __call__ params without modifying the __init__ ones.\u001b[39;00m\n",
      "        preprocess_params = {**self._preprocess_params, **preprocess_params}\n",
      "        forward_params = {**self._forward_params, **forward_params}\n",
      "        postprocess_params = {**self._postprocess_params, **postprocess_params}\n",
      "\n",
      "        self.call_count += \u001b[32m1\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.call_count > \u001b[32m10\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m self.framework == \u001b[33m\"pt\"\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m self.device.type == \u001b[33m\"cuda\"\u001b[39m:\n",
      "            logger.warning_once(\n",
      "                \u001b[33m\"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a\"\u001b[39m\n",
      "                \u001b[33m\" dataset\"\u001b[39m,\n",
      "            )\n",
      "\n",
      "        is_dataset = Dataset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m isinstance(inputs, Dataset)\n",
      "        is_generator = isinstance(inputs, types.GeneratorType)\n",
      "        is_list = isinstance(inputs, list)\n",
      "\n",
      "        is_iterable = is_dataset \u001b[38;5;28;01mor\u001b[39;00m is_generator \u001b[38;5;28;01mor\u001b[39;00m is_list\n",
      "\n",
      "        \u001b[38;5;66;03m# TODO make the get_iterator work also for `tf` (and `flax`).\u001b[39;00m\n",
      "        can_use_iterator = self.framework == \u001b[33m\"pt\"\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m (is_dataset \u001b[38;5;28;01mor\u001b[39;00m is_generator \u001b[38;5;28;01mor\u001b[39;00m is_list)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_list:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n",
      "                final_iterator = self.get_iterator(\n",
      "                    inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n",
      "                )\n",
      "                outputs = list(final_iterator)\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self.run_multi(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m can_use_iterator:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.get_iterator(\n",
      "                inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m is_iterable:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m self.framework == \u001b[33m\"pt\"\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m isinstance(self, ChunkPipeline):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m next(\n",
      "                iter(\n",
      "                    self.get_iterator(\n",
      "                        [inputs], num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n",
      "                    )\n",
      "                )\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001b[31mFile:\u001b[39m      ~/anaconda3/envs/v2v/lib/python3.12/site-packages/transformers/pipelines/base.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "model.__call__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# revert the tokenizer if multilingual inference is enabled\n",
    "if self.preset_language is None:\n",
    "    self.tokenizer = None\n",
    "\n",
    "# revert suppressed tokens if suppress_numerals is enabled\n",
    "if self.suppress_numerals:\n",
    "    self.options = replace(self.options, suppress_tokens=previous_suppress_tokens)\n",
    "\n",
    "return {\"segments\": segments, \"language\": language}\n",
    "\n",
    "def detect_language(self, audio: np.ndarray) -> str:\n",
    "if audio.shape[0] < N_SAMPLES:\n",
    "    print(\"Warning: audio is shorter than 30s, language detection may be inaccurate.\")\n",
    "model_n_mels = self.model.feat_kwargs.get(\"feature_size\")\n",
    "segment = log_mel_spectrogram(audio[: N_SAMPLES],\n",
    "                                n_mels=model_n_mels if model_n_mels is not None else 80,\n",
    "                                padding=0 if audio.shape[0] >= N_SAMPLES else N_SAMPLES - audio.shape[0])\n",
    "encoder_output = self.model.encode(segment)\n",
    "results = self.model.model.detect_language(encoder_output)\n",
    "language_token, language_probability = results[0][0]\n",
    "language = language_token[2:-2]\n",
    "print(f\"Detected language: {language} ({language_probability:.2f}) in first 30s of audio...\")\n",
    "return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v2v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
